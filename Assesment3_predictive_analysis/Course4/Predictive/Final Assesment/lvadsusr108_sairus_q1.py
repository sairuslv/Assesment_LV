# -*- coding: utf-8 -*-
"""LVADSUSR108_Sairus_Q1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UqwolU3lUDa4HvNTh-sDed9lE0SgN2PT
"""

import pandas as pd
import numpy as np
from collections import Counter
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier

df=pd.read_csv('/content/loan_approval.csv')
var_loan_df=df
df.head()

df.info() #  some space ahead of all col names

df.isnull().sum()

df.describe()

var_loan_df.columns = var_loan_df.columns.str.strip()

var_loan_df.isnull().sum() # no null values detected

target_distribution_corrected = var_loan_df['loan_status'].value_counts(normalize=True)
target_distribution_corrected

#target_distribution = var_loan_df['loan_status'].value_counts(normalize=True)

def remove_outliers(df, features):
    outlier_indices = []

    for feature in features:
        Q1 = np.percentile(df[feature], 25)
        Q3 = np.percentile(df[feature], 75)
        IQR = Q3 - Q1
        outlier_step = 1.5 * IQR
        feature_outlier_indices = df[(df[feature] < Q1 - outlier_step) | (df[feature] > Q3 + outlier_step)].index
        outlier_indices.extend(feature_outlier_indices)

    outlier_indices = [index for index, count in Counter(outlier_indices).items() if count > 2]
    df_cleaned = df.drop(outlier_indices)
    return df_cleaned

num_features=['no_of_dependents', 'income_annum', 'loan_amount', 'loan_term', 'cibil_score',
              'residential_assets_value', 'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']
var_loan_df_cleaned = remove_outliers(var_loan_df, num_features )
var_loan_df_cleaned.info()

categorical_features = ['education', 'self_employed']
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(), categorical_features)
])

var_X = var_loan_df_cleaned.drop('loan_status', axis=1)
var_y = var_loan_df_cleaned['loan_status']
var_X_train, var_X_test, var_y_train, var_y_test = train_test_split(var_X, var_y, test_size=0.2, random_state=42)

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier()
}

results = {}
for name, model in models.items():
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])
    pipeline.fit(var_X_train, var_y_train)
    var_y_pred = pipeline.predict(var_X_test)
    accuracy = accuracy_score(var_y_test, var_y_pred)
    conf_matrix = confusion_matrix(var_y_test, var_y_pred)
    results[name] = {"Accuracy": accuracy, "Confusion Matrix": conf_matrix}

for model_name, metrics in results.items():
    print(f"{model_name}: Accuracy = {metrics['Accuracy']:.2f}, Confusion Matrix = {metrics['Confusion Matrix']}")

















